{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DatasetとDataLoaderについて\n",
    "pytorchには、データセットを扱う基本要素として以下の二つがある。  \n",
    "1. `torch.utils.data.Dataset`  \n",
    "2. `torch,utils.data.DataLoader`  \n",
    "\n",
    "これらを組み合わせることで、データの使用を簡単にしてくれる。  \n",
    "\n",
    "(1) Datasetについて  \n",
    "> Datasetには、**サンプル**と。それに対応する**ラベル**が格納される  \n",
    "\n",
    "(2) DataLoadeについて  \n",
    "> Datasetを引数として渡すことで、イテレート」処理が可能なものへとラッピングする。  \n",
    "> イテレート処理 : 100このデータセットを10個ずつに分けて渡してくれるイメージ  \n",
    "\n",
    "## pytorchのDatasetについて\n",
    "pytorchでは、多くのデータセットが用意されていて、主に以下の三つに分けられる。  \n",
    "1. 画像データ : [画像データの詳細は](https://pytorch.org/docs/stable/torchvision/datasets.html)\n",
    "2. テキストデータ : [テキストデータの詳細](https://pytorch.org/docs/stable/torchvision/datasets.html)\n",
    "3. 音声データ : [音声データの詳細](https://pytorch.org/audio/stable/datasets.html)\n",
    "\n",
    "\n",
    "# Datasetからの読み込み  \n",
    "pytorchで用意されているDatasetを利用するには、主に、`TorchVision`を用いる。  \n",
    "以下、TorchVisionからFASION-MNISTをロードする方法を紹介する。  \n",
    "FASION-MNISTとは、60,000個の訓練データと10,000個のテストデータから構成された、Zalandoの記事画像のデータセットです。\n",
    "\n",
    "各サンプルは、28×28のグレースケール画像と、10クラスのうちの1つのラベルから構成されています。\n",
    "\n",
    "### TorchVisionを用いたデータのロード\n",
    "TorchVisionを用いてデータのロードを行う際には、以下のパラメータを使用する。\n",
    "1. `root` : train/testデータが格納されているパスを指定  \n",
    "2. `train` : 訓練データまたがテストデータを指定  \n",
    "3. `download=True` : rootにデータが村座しない場合、インターネットからダウンロードしてくる  \n",
    "4. `transform` `target_transofrm` : 特徴量とラベルの変換を指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasetによるデータの読み込み\n",
    "\n",
    "# trainデータの読み込み\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "# testデータの読み込み\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットの反復処理と可視化\n",
    "Datasetの特定のindexを指定するにはリスト操作と同様にすれば良い。`data[index]`  \n",
    "matplotlibを用いていくつかのデータを可視化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "\n",
    "figure = plt.figure(figsize=(8,8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols*rows+1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# カスタムデータセットの作成 (自分でデータせセットを作る)\n",
    "自分でカスタムしたDatasetクラスを作成する際には、以下の3つの関数を**必ず**実装する必要がある。  \n",
    "1. `__init__`  \n",
    "2. `__len__`  \n",
    "3. `__getitem__`  \n",
    "\n",
    "以下では仮に、\n",
    "FashionMNISTの画像データを`img_dir`フォルダに、  \n",
    "ラベルはcsvファイルとして、`annotations_file`として保存してあるとする。\n",
    "\n",
    "(1) `__init__`について\n",
    "> `__init__`関数はDatasetオブジェクトがインスタンス化されるときに1度だけ実行される。  \n",
    "> 画像、annotation_file, それらに対する変換処理の初期設定を行う。  \n",
    "\n",
    "(2) `__len__`について  \n",
    "> `__len__`関数は、データセットのサンプル数を返す関数  \n",
    "\n",
    "(3) `__getitem__`について  \n",
    "> `__getitem__`関数は、指定された`idx`に対応するサンプルをデータセットから読み込んで返す関数。  \n",
    "> ここでは、`index`に基づいて、画像ファイルのパスを特定し、`read_image`を使用して画像をテンソルに変換する。  \n",
    "> さらに、transform functionを必要に応じて適用し、最終的に辞書型でデータとラベルを返す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, \\\n",
    "                 transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        sample = {\"image\": image, \"label\":label}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoaderの使い方\n",
    "Datasetでは、indexを指定してデータを取り出すことができる。が、  \n",
    "実際には、ミニバッチ単位で取り出すことがおおい。(具体的には、10こずつランダムに取り出すのように)  \n",
    "また、過学習を防ぐために、**epochでデータをシャッフルする**  \n",
    "これらの操作を簡単にするためのAPIとして`DataLoader`が存在する。\n",
    "\n",
    "## DataLoaderを用いた反復処理\n",
    "第一に、`DataLoader`を使用するために、`Dataset`を読み込ませる。  \n",
    "その後、以下に示すようにして、各データとそれに対応するラベルを取り出すことができる。  \n",
    "このとき、`shuffle=True`とすることで、順番をシャッフルすることができる。  \n",
    "より詳細な情報は[データの読み込みの詳細](https://pytorch.org/docs/stable/data.html#data-loading-order-and-sampler)を参照  \n",
    "\n",
    "### さらなる詳細について\n",
    "`torch..utils.data`の詳細は[torch.utils.dataの詳細](https://pytorch.org/docs/stable/data.html)を参照"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# データセットを読み込ませる\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape : {train_feature.size()}\")\n",
    "print(f\"Labels batch shape : {train_labels.size()}\")\n",
    "img = train_feature[0].squeeze()\n",
    "label = train_labels[0]\n",
    "print(f\"Label : {label}\")\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f5b1a9f36cac5504d3212872bcc323699452b76dcccf68776354c7e475628a4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
