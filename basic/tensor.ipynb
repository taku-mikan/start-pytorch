{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# テンソルについて\n",
    "テンソルとは、配列や行列に似たデータ構造の一つ。  \n",
    "pytorchにおいては、モデルの入出力やパラメータの表現などに用いられる。  \n",
    "numpyのndarrayとの違いは、自動微分に最適化されていること、GPUなどでの使用が可能なこと  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpyとpytorchのimport \n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テンソルの初期化 (作成)\n",
    "\n",
    "テンソルの作成にはいくつかの方法がある。\n",
    "1. データから直接テンソル化する方法 : `torch.tensor`の利用\n",
    "2. numpy arrayのテンソル化 : `torch.from_numpy`の利用\n",
    "3. 他のテンソルからの作成 : `torch.*_like`の利用\n",
    "    > 他のテンソルから新規のテンソルを作成する場合、明示的に上書きすることを示さない限り、  \n",
    "    > **引数のテンソルのプロパティ(形状やデータ型)を保持** する\n",
    "4. ランダム値や定数でのテンソルの作成 : `torch.rand` `torch.ones` `torch.zeros`の利用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データから直接テンソル化\n",
    "data = [[1,2], [3,4]] # 元データをリストで作成\n",
    "x_data = torch.tensor(data)\n",
    "print(type(x_data))\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy arrayからテンソル生成\n",
    "np_array = np.array(data)\n",
    "print(type(np_array))\n",
    "print(np_array)\n",
    "print(\"*\" * 30)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "print(type(x_np))\n",
    "print(x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 他のテンソルからの生成\n",
    "x_ones = torch.ones_like(x_data) # x_dataの特性（プロパティ）を維持\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # x_dataのdatatypeを上書き更新\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新規作成するときは明示的に形状を指定\n",
    "shape = (2, 3)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor : \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor : \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor : \\n {zeros_tensor} \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# テンソルの属性について\n",
    "属性には3種類存在し、**形状(shape)**, **データ型(dtype)**, **保存されているデバイス(device)** がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 属性の確認\n",
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Shape of Tensor : {tensor.shape}\")\n",
    "print(f\"Datatype of Tensor : {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on : {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# テンソルの操作について\n",
    "pytorch上では、テンソルに対して、100を越える様々なテンソル演算が可能。  \n",
    "詳細は[pytoechでの様々な演算](https://pytorch.org/docs/stable/torch.html)こちら  \n",
    "\n",
    "さらに、  \n",
    "デフォルトでは、テンソルはCPU上で作成される。  \n",
    "そのため、GPUを使用する場合には、明示的に`.to`メソッドを用いて、テンソルをGPU上へ移動させる。  \n",
    "ただしこのとき、大きなテンソルをデバイス間でコピーすると、時間とメモリの面でコストがかかることに注意\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPUが使用可能であれば、以下のようにしてテンソルを移動させる\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpyのようなtensorに操作\n",
    "tensor = torch.ones(4,4)\n",
    "print(\"First row : \", tensor[0])\n",
    "print(\"First column : \", tensor[:, 0])\n",
    "print(\"Last column\", tensor[..., -1])\n",
    "tensor[:, 1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# テンソルの結合\n",
    "`torch.cat`を使用することで、テンソルを特定の次元に沿って結合させることができる。  \n",
    "`torch.stack`も確認しておく。詳細はこちら[torch.stackについて](https://pytorch.org/docs/stable/generated/torch.stack.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cat\n",
    "t1 = torch.cat([tensor, tensor , tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 算術演算について\n",
    "# 2つのテンソルの行列の掛け算。y1~y3は同じ結果となる\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "y3 = torch.rand_like(tensor)\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "\n",
    "# 一方以下のzは要素ごとの積 ; z1~z3は同じ値\n",
    "z1 = tensor * tensor \n",
    "z2 = tensor.mul(tensor)\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1要素のテンソルの値の抽出\n",
    "1要素のテンソルを扱う場合には、`.item()`でpythonの数値型に変換が可能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## インプレース操作\n",
    "演算をオペランドに格納する演算をインプレースという。  \n",
    "メソッドの最後、接頭辞として操作名に`_`がつく  \n",
    "例) `x.copy_(x)` , `x.t_()`など  \n",
    "\n",
    "<注意>  \n",
    "インプレース操作は、メモリの節約になるが、**演算履歴が失われるため、びぶんを計算する際に問題になる**。このため、微分を計算するときは使用するのを控えた方がよい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tensor, \"\\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpyとの変換\n",
    "CPU上のテンソルとnumpy arrayは同じメモリを共有することができ、相互変換が容易  \n",
    "1. Tensor -> Numpy : `.numpy()`  \n",
    "2. numpy -> tensor : `torch.from_numpy()` \n",
    " \n",
    "<注意>  \n",
    "どちらも共に、変換を変化させると同時に元も変換する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor -> Numpy\n",
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")\n",
    "\n",
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy -> Tensor\n",
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)\n",
    "\n",
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f5b1a9f36cac5504d3212872bcc323699452b76dcccf68776354c7e475628a4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
